---
title: "Extracting + cleaning data for interim analysis of Dyna-CORE study"
authors: 
"Lara Puhlmann (lara.puhlmann@lir-mainz.de)" 
"Matthias Zerban (matthias.zerban@unimedizin-mainz.de)"  
"Jeroen Weermeijer (jeroen.weermeijer@kuleuven.be)"
"Haakon Engen"

date: "APril 10th, 2020"
---

```{r setup, include=FALSE}
#  - this version includes data sanity checks -

# NOTE REMAINING ISSUES: 
# - completion time is negative sometimes
# - current location variables does not work <= fixed?

# definition of Europe based on United Nations, Department of Economic and Social Affairs, Population Division (2019). World Population Prospects 2019, Online Edition. Rev. 1.

#
# WARNING: Only run once! 
#

library(knitr)
require(foreign)
require(plyr)
require(dplyr)
require(stringr)
require(BBmisc)
#require(formattable)
#require(Hmisc)
#require(corrplot)

source("rename.R") #renames variables
source("formatting.R") #groups occupation and occupational status in lists

numextract <- function(string){str_extract(string, "\\-*\\d+\\.*\\d*")} # extracts numeric part free response

```

```{r Read and format data}
# load data - currently set up to work with owncloud. Data must have 171 columns!

#data_en <- read_csv("DynaCORE - the DynaMORE study on psychological responses to the Corona.csv", sep = ",", stringsAsFactors = FALSE)
#data_text <- read_csv("DynaCORE-C_text_answers.csv", sep = ",", stringsAsFactors = FALSE) # text version 

# user-specific path [change accordingly]:
data_en = read.csv("C:/Users/Nutzer/ownCloud/DynaCORE_C/DynaCORE - the DynaMORE study on psychological responses to the Corona.csv", sep = ",", stringsAsFactors = FALSE)
data_text = read.csv("C:/Users/Nutzer/ownCloud/DynaCORE_C/DynaCORE-C_text_answers.csv", sep = ",", stringsAsFactors = FALSE)

data_en = rename(data_en) #rename variables
data_en = formatting(data_en) #group occupation + status in lists

data_en = data_en[which(!is.na(data_en$Respondent.ID)),] # remove row without respondent ID

# indicate missings in questionnaires
data_en[,c(68:154,156:167)] <- lapply(data_en[,c(68:154,156:167)], as.numeric) # questionnaires
data_en$missings <- rowSums(is.na(data_en[,c(68:154,156:167)]))

# indicate missing data in covariates:
data_en$missing.cov = NA

# 1) anyone away from their residence and not specifying the country or city of their current location
xx  = which(data_en$current.stay.out.of.town==1 & nchar(data_en$current.stay.out.of.town.country)==0 | data_en$current.stay.out.of.town==1 & nchar(data_en$current.stay.out.of.town.city)==0)
data_en$missing.cov[xx] = 1

# 2): missing symptom specification
xx = which(data_en$infection.test.status=="0" & is.na(as.numeric(data_en$symptom.severity)))
data_en$missing.cov[xx] = 1

```

```{r quality check income, include = FALSE}
i <- which.first(data_en$Respondent.ID[2]==data_text$Respondent.ID) -1
data_en$check_ID_text <- data_text$Respondent.ID[i:nrow(data_text)]
data_en$check_income_text <- data_text$What.is.your.approximate.average.annual.household.income..please.estimate.in.Euro..[i:nrow(data_text)]
test <- data_en[,c(ncol(data_en)-1, ncol(data_en))] #subset to check income variable
test$ID <- data_en$Respondent.ID
isTRUE(test$check_ID_text[nrow(test)]==test$ID[nrow(test)])
test$income <- data_en$household.income
table(test$income) 
#            1       10       11       12       13       14        2        3        4        5        6        7 
#3174      416      409      205      123       60      130      936      742      777     1273     2045     1392 
#  8        9 Response 
#750      422        1 

table(test$income[test$check_income_text=="â‚¬25,000-â‚¬49,999"]) 
#there are multiple levels coded to this response:
#    10    6 
#1  409 2045

```

```{r date & time}

#split month-day-year date + time col into two col, one with the date format, one with correct time
for(i in 1:length(data_en$Respondent.ID)){
  start = strsplit(data_en$Start.Date[i], " ")
  data_en$Start.Date[i] = start[[1]][1]
  data_en$Start.Time[i] = paste(start[[1]][2], start[[1]][3])
  
  end = strsplit(data_en$End.Date[i], " ")
  data_en$End.Date[i] = end[[1]][1]
  data_en$End.Time[i] = paste(end[[1]][2], end[[1]][3])
}

# dealing with different separators for date outputs (e.g. mm/dd/yyyy vs. mm.dd.yyyy).
data_en$Start.Date = gsub(".", "/", data_en$Start.Date, fixed=TRUE) #mm.dd.yyyy becomes mm/dd/yyyy

#convert month-day-year to year-month-day date, then to POSIXlt
data_en$Start.Date = as.Date(data_en$Start.Date, tryFormats = c("%m-%d-%Y", "%m/%d/%Y"), optional = FALSE)
data_en$End.Date = as.Date(data_en$End.Date, tryFormats = c("%m-%d-%Y", "%m/%d/%Y"), optional = FALSE)
data_en$Start.Date = as.POSIXlt(paste(data_en$Start.Date), tz = "Europe/Berlin", format="%Y-%m-%d")
data_en$End.Date = as.POSIXlt(paste(data_en$End.Date), tz = "Europe/Berlin", format="%Y-%m-%d")
data_en$Start.DateTime = as.POSIXlt(paste(data_en$Start.Date, data_en$Start.Time), tz = "Europe/Berlin", format="%Y-%m-%d %I:%M:%S %p")
data_en$End.DateTime = as.POSIXlt(paste(data_en$End.Date, data_en$End.Time), tz = "Europe/Berlin", format="%Y-%m-%d %I:%M:%S %p")

# #test
# data_en$Start.Date[4] #should give year/month/day GMT
# data_en$End.Date[4] #should give year/month/day GMT
# data_en$Start.DateTime[4] #should give year/month/day hour/minutes/seconds GMT
# data_en$End.DateTime[4] #should give year/month/day hour/minutes/seconds GMT

#completion time
data_en$completionTime = difftime(data_en$End.DateTime, data_en$Start.DateTime)
# test: data_en$completionTime[3] #gives time difference in mins
data_en$completionTime <- as.numeric(data_en$completionTime, units="secs")

```

```{r data up to 5000th complete response from European residents, include=FALSE}

Europe = c(2, 4, 11, 17, 18, 23, 28, 45, 48, 51, 60, 63, 64, 68, 70, 77, 80, 81, 86, 88, 98, 103, 104, 105, 111, 117, 119, 127, 132, 142, 143, 146, 147, 148, 154, 158, 162, 163, 168, 174, 175, 180, 191, 193)

data_en = data_en[which(data_en$country.of.residence %in% Europe),] # exclude all non-European residents
data_en = data_en[order(data_en$End.DateTime),] # sort by completion date + time

data_en$complete.eu = NA #count of complete responses from European residents
c = 0
for(i in 1:length(data_en$complete.eu)){
  if (data_en$missings[i] == 0 && is.na(data_en$missing.cov[i])){
  c = c+1
  data_en$complete.eu[i] = c
  }
}
data_en = data_en[1:which(data_en$complete.eu==5000),] # keep data up until the 5000th complete response
dim(data_en[data_en$missings == 0 &is.na(data_en$missing.cov),]) # should be 5000
dim(data_en[data_en$missings > 0|!is.na(data_en$missing.cov),]) # should be the remaining

max(data_en$End.DateTime)
data_en$complete.eu[which(data_en$End.DateTime == max(data_en$End.DateTime))]
data_en$End.DateTime[length(data_en$Respondent.ID)] # pull date

```

```{r clean "out of town" response in char format, include = FALSE}

# set "out of town" response of people naming a different country than their country of residence to yes
xx = which(data_en$current.stay.out.of.town.country[which(data_en$current.stay.out.of.town=="2" & data_en$current.stay.out.of.town.country !="")] != data_en$country.of.residence[which(data_en$current.stay.out.of.town=="2" & data_en$current.stay.out.of.town.country !="")])

data_en$current.stay.out.of.town[which(data_en$current.stay.out.of.town=="2" & data_en$current.stay.out.of.town.country !="")][xx] = "1"

# set responses of people not out of town and naming the same as their country of residence to empty
length(which(data_en$current.stay.out.of.town.country[which(data_en$current.stay.out.of.town=="2")] != ""))
length(which(data_en$current.stay.out.of.town.country[which(data_en$current.stay.out.of.town=="2"&!is.na(data_en$complete.eu))] != ""))

data_en$current.stay.out.of.town.country[which(data_en$current.stay.out.of.town=="2" & data_en$current.stay.out.of.town.country != "")] <- ""

data_en$current.location <- ifelse(data_en$current.stay.out.of.town == '1', data_en$current.stay.out.of.town.country, data_en$country.of.residence)
 
# test
data_en$country.of.residence[which(data_en$current.stay.out.of.town==1& data_en$missings ==0)][17] 
data_en$current.stay.out.of.town.country[which(data_en$current.stay.out.of.town==1& data_en$missings ==0)][17] 
data_en$current.location[which(data_en$current.stay.out.of.town==1& data_en$missings ==0)][17]

# how many are not currently in Europe?
length(which(!(data_en$current.stay.out.of.town.country %in% Europe) & data_en$current.stay.out.of.town.country !=""))
data_en$current.stay.out.of.town.country[which(!(data_en$current.stay.out.of.town.country %in% Europe) & data_en$current.stay.out.of.town.country !="")]
```

```{r  format covariates}
#data_en[,c(68:154,156:167)] <- lapply(data_en[,c(68:154,156:167)], as.numeric) # questionnaires
data_en[,c(1:2, 10:12,14:16, 18:19, 53:54, 58:59, 60:61,64)] <- lapply(data_en[,c(1:2, 10:12,14:16, 18:19, 53:54, 58:59, 60:61,64)], as.factor)# covariates

# name most frequent countries
data_en$country.of.residence = revalue(data_en$country.of.residence, 
      c("68" = "Germany", "142" = "Poland", "18" = "Belgium", "88" = "Italy", "64" = "France", "11" = "Austria", "127" = "Netherlands", "158" = "Serbia", "80" = "Hungary", "175" = "Switzerland"))

data_en$household.income = factor(data_en$household.income, order = TRUE)
data_en$health.status = factor(data_en$health.status, order = TRUE)
data_en$symptom.severity = factor(data_en$symptom.severity, order = TRUE)

data_en$people.in.household.under.18 = as.numeric(data_en$people.in.household.under.18)
data_en$opinion.about.authorities.measures = as.numeric(data_en$opinion.about.authorities.measures)
data_en$adherence.to.recommended.procedures = as.numeric(data_en$adherence.to.recommended.procedures)

# people.in.household as continuous
data_en$people.in.household.cont = as.numeric(data_en$people.in.household)-1 # factor 0, meaning more than 6, was recoded to 1
xx = as.numeric(numextract(data_en$X.28))
xx[which(xx==0)] = 1
data_en$people.in.household.cont[which(data_en$people.in.household.cont == 0)] = xx[!is.na(xx)]
data_en$people.in.household.cont[which(data_en$people.in.household.cont == 3)] = 3.5
data_en$people.in.household.cont[which(data_en$people.in.household.cont == 4)] = 5.5


# date of Corona test
data_en$infection.test.status.date = gsub(".", "/", data_en$infection.test.status.date, fixed=TRUE)
data_en$infection.test.status.date[which(nchar(data_en$infection.test.status.date)<5)]=NA # set all that are not a date to NA
data_en$infection.test.status.date = as.Date(data_en$infection.test.status.date, tryFormats = c("%m-%d-%Y", "%m/%d/%Y"), optional = FALSE) # convert month-day-year to year-month-day date
data_en$infection.test.status.date = as.POSIXlt(paste(data_en$infection.test.status.date), tz = "Europe/Berlin", format="%Y-%m-%d") # date as POSIXlt
```

```{r covariates: plausibility checks & cleaning, include = FALSE}
# remaining incomplete covariates among those without missings - should all be 0
data_en.complete = data_en[which(!is.na(data_en$complete.eu)),]
#length(which(data_en.complete$current.stay.out.of.town==1 & data_en.complete$current.stay.out.of.town.city==""))
length(which(data_en.complete$people.in.household==0 & nchar(data_en.complete$X.28)==0))
length(which(data_en.complete$infection.test.status==0 & is.na(as.numeric(data_en.complete$symptom.severity))))


###### age #####

data_en$age.fulltext = data_en$age
data_en$age = gsub("o", "0", data_en$age) #account for people accidently typing 'o' instead of '0'

# extract the numeric component from age response
data_en$age = numextract(data_en$age)
data_en$age = as.numeric(data_en$age)
data_en$age[which(data_en$age > 100)] = NA
length(which(is.na(data_en$age))) # just the one

# if any ages are 0, this could be due to a leading o that was substituted above. Check fulltext:
data_en$age.fulltext[which(data_en$age==0)] # -> one person, who says to be 41 soon
data_en$age[which(data_en$age==0)] = 41 # recode this person:

# check invalid age responses 
which(data_en$age < 18)
which(data_en$age[which(!is.na(data_en$complete.eu))] < 18)
which(is.na(data_en$age[which(!is.na(data_en$complete.eu))]))

# exclude those resposes
data_en$Respondent.ID[which(data_en$age < 18)]<- NA
data_en$Respondent.ID[which(is.na(data_en$age))]<- NA
xx = which(is.na(data_en$Respondent.ID))
if(length(xx)>0){data_en = data_en[-xx,]}

###### education #####

data_en$years.of.education.fulltext = data_en$years.of.education
data_en$years.of.education = numextract(data_en$years.of.education) # extract the numeric component of response
data_en$years.of.education = as.numeric(data_en$years.of.education)
# if people fail to add their years of education to a total, they may end up with too low of a value. "years.of.education.fulltext" includes the full answer for years.of.education for anyone with less than 10 years

length(which(data_en$years.of.education > data_en$age)) # indicate people with more years of education than age
length(which(data_en$years.of.education[which(!is.na(data_en$complete.eu))] > data_en$age[which(!is.na(data_en$complete.eu))]))

for(i in 1:length(data_en$Respondent.ID)){
  if (!is.na(data_en$years.of.education[i])) {
    if(data_en$years.of.education[i] > data_en$age[i]){
      data_en$years.of.education[i] = NA
    }
    if(!is.na(data_en$years.of.education[i]) && data_en$years.of.education[i] > 10){
      data_en$years.of.education.fulltext[i] = NA
    }
  }
}

# check fulltest answers to make sure this was not due to typos or nor summing the total years of 
data_en$years.of.education.fulltext[which(!is.na(data_en$years.of.education.fulltext))] # all plausible

####  inconsistent responses ####

# count cases where more/same as total nr of people in household are underage
xx = which(data_en$people.in.household.cont+0.5<=data_en$people.in.household.under.18)
xx = which(data_en$people.in.household.cont[which(!is.na(data_en$complete.eu))]+0.5<=data_en$people.in.household.under.18[which(!is.na(data_en$complete.eu))])

# set symptom ratings of those not being COVID positive to NA
xx = which(data_en$symptom.severity[which(data_en$infection.test.status==1)] > 1) # symptom severity above 1 although saying they were not tested pos
#xx = which(data_en.complete$symptom.severity[which(data_en.complete$infection.test.status==1)] > 1)
data_en$symptom.severity[which(data_en$infection.test.status==1)] <- NA 


### occupation

# variable with occupation of people with only one occupation
data_en$occupation.if.only.one <- as.character(data_en$occupation)
data_en$occupation.if.only.one <- as.numeric(data_en$occupation.if.only.one)
# variable with occupational status of people with only one indicated
data_en$occupational.status.if.only.one <- as.character(data_en$occupational.status)
data_en$occupational.status.if.only.one <- as.numeric(data_en$occupational.status.if.only.one)

### set cases with mismatch in occupation to NA
data_en$not.working.12 <- lapply(data_en$occupation, function(ch) grep("16", ch))
data_en$not.working.12[sapply(data_en$not.working.12, function(x) length(x)==0)] <- NA

employed = c("1", "2", "3", "4")
not.employed = c("7", "8", "9", "10", "12") #parental leave, sick leave, unemployment w/ or w/o benefits, retired
data_en$employed.13 <- lapply(data_en$occupational.status, function(ch) grep(paste(employed, collapse="|"), ch))
data_en$not.employed.13 <- lapply(data_en$occupational.status, function(ch) grep(paste(not.employed, collapse="|"), ch))
data_en$employed.13[sapply(data_en$employed.13, function(x) length(x)==0)] <- NA
data_en$not.employed.13[sapply(data_en$not.employed.13, function(x) length(x)==0)] <- NA

# find people that are unemployed in 12 but working in 13
index = which(!is.na(data_en$not.working.12)) %in% which(!is.na(data_en$employed.13))
xx = which(!is.na(data_en$not.working.12))[index]
data_en$occupation[xx] <- NA
data_en$occupational.status[xx] <- NA

# add 'not working' to occupation of all individuals listing forms of not working in 13
index = which(is.na(data_en$not.working.12)) %in% which(!is.na(data_en$not.employed.13))
xx = which(is.na(data_en$not.working.12))[index]
data_en$occupation[xx][[1]][length(data_en$occupation[xx][[1]])+1] <- 16

# drop empty levels
data_en$gender = droplevels(data_en$gender)
data_en$nationality = droplevels(data_en$nationality)
data_en$country.of.residence = droplevels(data_en$country.of.residence)
data_en$current.stay.out.of.town = droplevels(data_en$current.stay.out.of.town)
data_en$current.stay.out.of.town.country = droplevels(data_en$current.stay.out.of.town.country)
data_en$infection.test.status = droplevels(data_en$infection.test.status)
data_en$survey.language = droplevels(data_en$survey.language)
data_en$relationship.status = droplevels(data_en$relationship.status)
data_en$people.in.household = droplevels(data_en$people.in.household)

```

```{r data checks, include=FALSE}

# indicate individuals who report COVID symptoms but in stressor exposure said this situation did not happen
data_en$symptom.inconsistency = NA
data_en$symptom.inconsistency[which(data_en$symptom.severity >0 & data_en$CE_01 == 0)] = 1
sum(data_en$symptom.inconsistency, na.rm = T) # -> none

# indicate individuals who report being in a risk group but in stressor exposure said to risk group "this situation did not happen"
data_en$risk.group.inconsistency = NA
data_en$risk.group.inconsistency[which(data_en$risk.group == 1 & data_en$CE_04 == 0)] = 1
sum(data_en$risk.group.inconsistency, na.rm = T)

## find people who provide a stressor rating > 0 in the free answers but fail to describe the stressor
length(which(data_en$CE_30>0 & nchar(data_en$CE_30_text) == 0))
length(which(data_en.complete$CE_30>0 & nchar(data_en.complete$CE_30_text) == 0))

length(which(data_en$GE_12>0 & nchar(data_en$GE_12_text) == 0))
length(which(data_en.complete$GE_12>0 & nchar(data_en.complete$GE_12_text) == 0))
# 

# number of responses per country
sort( table(unlist(data_en$country.of.residence)),decreasing=TRUE)

# frequency table of 10 most frequent countries
sort( table(unlist(data_en$country.of.residence)),decreasing=TRUE)[1:10]

```

```{r old income coding}
 
data_en$household.income.old = factor(data_en$household.income, order = TRUE)
test <- data_en[c("Respondent.ID","check_ID_text","household.income","household.income.old", "check_income_text")] #to check corresponding factors
data_en$household.income.old <- mapvalues(data_en$household.income.old,c(1,2,3,4,5,6,7,8,9,10,11,12), c(1,1,1,1,1,6,7,8,9,6,11,12))
```

```{r restructure questionnaire variables}

#data_en[,c(68:154,156:167)] <- lapply(data_en[,c(68:154,156:167)], as.numeric)
#data_en <- data_en[data_en$missings == 0,] # remove any cases with missings

# Mental Health Problems [P]
data_en$CM_07 <- 5 - data_en$CM_07
term <- "CM"
GHQ <- grep(term, names(data_en))
GHQrecode <- function(x){recode(x, '1'=0L, '2'=1L, '3'=2L, '4'=3L)}
data_en[GHQ] <- lapply(data_en[GHQ], GHQrecode)
GHQ <- GHQ[1:12]
data_en$P <- rowSums(data_en[GHQ])

# percieved social support [PSS]
term <- "H2_"
PSSindex <- grep(term, names(data_en))
PSSindex <- PSSindex[1:7]
data_en$PSS <- rowSums(data_en[PSSindex])

# Optimism:
data_en$OPT <- as.numeric(data_en$H3_01)

# Perceived general self efficacy
term <-"H4_"
GSEindex <- grep(term, names(data_en))
data_en$GSE <- rowSums(data_en[GSEindex])

# self-percieved resilience (BRS)
term <- "H5_"
BRS <- grep(term, names(data_en))
BRSrec <- c("H5_02", "H5_04", "H5_06")
data_en[,BRSrec] <- 6 - data_en[,BRSrec]
data_en$REC <- rowMeans(data_en[BRS])

# BFI Neuroticism
data_en$H6_01 <- 6 - data_en$H6_01
term <- "H6_"
BFI <- grep(term, names(data_en))
BFIrecode <- function(x){recode(x, '1'=-2L, '2'=-1L, '3'=0L, '4'=1L,'5'=2L)}
data_en[BFI] <- lapply(data_en[BFI], BFIrecode)
data_en$NEU <- rowSums(data_en[BFI])

# Behavioral Coping style
term <- "COPE"
COPE <- grep(term, names(data_en))
COPE <- COPE[c(1:5,7:9)]
data_en$BCS <- rowSums(data_en[COPE])

# CERQ
term <- "CERQ"
CERQ <- grep(term, names(data_en))
data_en$CERQSum <- rowSums(data_en[CERQ])

# Positive Appraisal Style:
PAS <- data_en[,c(CERQ, 106, 110 )]
PAS[,c("H1_COPE_18","H1_COPE_28")] <- PAS[,c("H1_COPE_18","H1_COPE_28")]*5/4 #rescale
data_en$PAS <- rowMeans(PAS)

# Corona specific appraisal
term <- "H1_Cor_"
PAC <- grep(term, names(data_en))
data_en$PAC <- rowSums(data_en[PAC])

```

```{r calculation of stressors}

# SCM = stressor count method
# SSM = stressor severity method

#Corona pandmeic related stressors:
term <- "CE_"
CE <- grep(term, names(data_en))
CE <- CE[1:30]
data_en$Es.SCM <- rowSums(data_en[CE] >0) #stressor count
data_en$Es.SSM <- rowSums(data_en[CE])/5 #weighted

#general stressors:
term <- "GE_"
GE <- grep(term, names(data_en))
GE <- GE[1:12]
data_en$Eg.SCM <- rowSums(data_en[GE] >0) #stressor count
data_en$Eg.SSM <- rowSums(data_en[GE])/5 #weighted

#combined:
Eall <- c(grep("GE_", names(data_en))[1:12], grep("CE_", names(data_en))[1:30])
data_en$Ec.SCM <- rowSums(data_en[Eall] >0) #stressor count
data_en$Ec.SSM <- rowSums(data_en[Eall])/5 #weighted

# test
which(data_en$Ec.SCM!=rowSums(data_en[ , c("Eg.SCM" ,"Es.SCM")])) # should be 0

```

```{r calculate SR Scores}

# stressor count method
m1 <- summary(lm(scale(P)~scale(Eg.SCM),data= data_en[!is.na(data_en$Eg.SCM),]))
data_en$SR_Eg.SCM[!is.na(data_en$Eg.SCM)] <-as.numeric(scale(resid(m1)))

m2 <- summary(lm(scale(P)~scale(Es.SCM),data= data_en[!is.na(data_en$Es.SCM),]))
data_en$SR_Es.SCM[!is.na(data_en$Es.SCM)] <-as.numeric(scale(resid(m2)))

m3 <- summary(lm(scale(P)~scale(Ec.SCM),data= data_en[!is.na(data_en$Ec.SCM),]))
data_en$SR_c.SCM[!is.na(data_en$Ec.SCM)] <-as.numeric(scale(resid(m3)))

# stressor severity method
m4 <- summary(lm(scale(P)~scale(Eg.SSM),data= data_en[!is.na(data_en$Eg.SSM),]))
data_en$SR_Eg.SSM[!is.na(data_en$Eg.SSM)] <-as.numeric(scale(resid(m4)))

m5 <- summary(lm(scale(P)~scale(Es.SSM),data= data_en[!is.na(data_en$Es.SSM),]))
data_en$SR_Es.SSM[!is.na(data_en$Es.SSM)] <-as.numeric(scale(resid(m5)))

m6 <- summary(lm(scale(P)~scale(Ec.SSM),data= data_en[!is.na(data_en$Ec.SSM),]))
data_en$SR_c.SSM[!is.na(data_en$Ec.SSM)] <-as.numeric(scale(resid(m6)))

```

```{r generate subgroups . remove?}

# subjects in Europe
xx = which(data_en$current.location %in% Europe)
data_en$in.eu = 0
data_en$in.eu[xx] = 1
data_en$in.eu = as.factor(data_en$in.eu)

# index people with potentially precarious job conditions: freelancer, self-employed, temp contract, unemployed, by excluding everyone with a stable status
stable.occupational.status = c("1", "3", "7", "8", "11", "12")
insecure.occulational.status = c("2", "4", "5", "6", "9", "10")

index.stable.occupational.status <- lapply(data_en$occupational.status, function(ch) grep(paste(stable.occupational.status, collapse="|"), ch))
index.stable.occupational.status[sapply(index.stable.occupational.status, function(x) length(x)==0)] <- NA

index.insecure.occupational.status <- lapply(data_en$occupational.status, function(ch) grep(paste(insecure.occulational.status, collapse="|"), ch))
index.insecure.occupational.status[sapply(index.insecure.occupational.status, function(x) length(x)==0)] <- NA

data_en$unstable.occupational.status = NA 
data_en$unstable.occupational.status[which(!is.na(index.stable.occupational.status))] = 0 # 0 = no, stable status
data_en$unstable.occupational.status[which(is.na(index.stable.occupational.status)&!is.na(index.insecure.occupational.status))] = 1 # 1 = yes, unstable status (and no additional stable status)
```

```{r response variance and completion time}

# exclude subjects with no response variance (check block-wise for all questionnaires with more than 2 items)
var = matrix(NA, nrow = length(data_en$Respondent.ID), ncol = 8)
for (i in 1:nrow(data_en)){ 
  var[i,1] = (var(as.vector(as.matrix(data_en[i, GHQ])))) 
  var[i,2] = (var(as.vector(as.matrix(data_en[i, PSSindex])))) 
  var[i,3] = (var(as.vector(as.matrix(data_en[i, GSEindex])))) #object asku not found
  var[i,4] = (var(as.vector(as.matrix(data_en[i, BRS])))) 
  var[i,5] = (var(as.vector(as.matrix(data_en[i, COPE])))) 
  var[i,6] = (var(as.vector(as.matrix(data_en[i, CERQ])))) 
  var[i,7] = (var(as.vector(as.matrix(data_en[i, CE])))) 
  var[i,8] = (var(as.vector(as.matrix(data_en[i, GE])))) 
}

data_en$response_variance = rowSums(var)
# exclude subject with 0 average response variance
data_en$Respondent.ID[which(data_en$response_variance == 0)] # none

# distributions
hist(data_en$response_variance) # distribution of response variance
hist(data_en$age) # distribution of age
hist(data_en$completionTime/60) # distribution of completion time
hist(data_en$completionTime[which(data_en$completionTime/60<1440)]/60) # distribution of completion time under 1 day

length(which(data_en$completionTime/60>1440)) # longer than 1 day
length(which(data_en$completionTime[which(!is.na(data_en$complete.eu))]/60>1440))
length(which(data_en$completionTime/60>2880)) # longer than 2 days
length(which(data_en$completionTime[which(!is.na(data_en$complete.eu))]/60>2880))

# consider excluding subjects with unusually short completion time
#t = threshold completion time
# data_en$Respondent.ID[which(data_en$completionTime < t)]<- NA

#### exclude all subjects that were set to NA:
xx = which(is.na(data_en$Respondent.ID))
if(length(xx)>0){data_en = data_en[-xx,]}

# remove unnecessary columns 
xx = grep("X", colnames(data_en))
data_en = data_en[-xx]
# note that in the real data, the above step will also exclude the column IP address

data_en = data_en[, colSums(is.na(data_en)) != nrow(data_en)]


save(data_en, file = "data_en.RData")
```
```{r first analysis of data - perhaps move to analysis script?}
require(stargazer)

# correlations of stressors
res <- cor(my_data)
round(res, 2)

# compare model fits

# stressor count method
xx = !is.na(data_en$Eg.SCM) & !is.na(data_en$Es.SCM) & !is.na(data_en$Ec.SCM) # match sample size

m1 <- lm(scale(P)~scale(Eg.SCM),data= data_en[xx,])
m2 <- lm(scale(P)~scale(Es.SCM),data= data_en[xx,])
m3 <- lm(scale(P)~scale(Ec.SCM),data= data_en[xx,])

anova(m1)
anova(m1, m2, m3, test="F")

# stressor severity method
xx =  !is.na(data_en$Eg.SSM) & !is.na(data_en$Es.SSM) & !is.na(data_en$Ec.SSM) # match sample size
m4 <- lm(scale(P)~scale(Eg.SSM),data= data_en[xx,])
m5 <- lm(scale(P)~scale(Es.SSM),data= data_en[xx,])
m6 <- lm(scale(P)~scale(Ec.SSM),data= data_en[xx,])

# examine explained variance
summary(m1)$r.squared
summary(m2)$r.squared
summary(m3)$r.squared
summary(m4)$r.squared
summary(m5)$r.squared
summary(m6)$r.squared

anova(m6)
anova(m4, m5, m6, test="F")

anova(m1, m2, m3, m4, m5, m6)

correlation.matrix <- cor(attitude[,c("rating","complaints","privileges")])stargazer(correlation.matrix, title="Correlation Matrix")

# correlations of stressor residuals


```

```{r old table code - remove?}
# 
# ######### table 1: sample demographics and health status 
# # (all the initial basic variables and people‘s thinking about how the crisis is managed).
# 
# ''' very awkward solution from myside; preparing aver single variable as a vector and rbind in the end to a dataframe.. /mz
# 
# demovar <- c("age", "gender", "current.stay.out.of.town", "years.of.education", "occupational.status", 
#              "household.income", "relationship.status", "people.in.household", "diagnosed.mental.health", 
#              "risk.group", "infection.test.status", "quarantine.status", "opinion.about.authorities.measures", 
#              "adherence.to.recommended.procedures" )
# demog <- data_en[demovar]
# age <- summary(demog$age)
# gender <- 
# demog.summary <- data.frame()
# age_descr <- c("Median age (range)", str_glue("{age[3]}","({age[1]}-{age[6]})"))
# Gender_title <- c("Gender", "")
# Male
# '''
# #demog.summary <- rbind(age_descr,sex_title)
# 
# 
# 
# ######### table 2: average values + SD of the sample in all the dependent and independent variables
# 
# ###step 1: extract all variables of interest into a new dataframe
# ##NOTE: excel sheet SR_Ec.SCM SR_Ec.SSM do not match in R, in R they are defined as SR_c.SCM and SR_c.SSM - if adjusted, change in line below and code above
# variables.of.interest = data_en[, c("SR_Eg.SCM", "SR_Es.SCM", "SR_c.SCM", "SR_Eg.SSM", "SR_Es.SSM", "SR_c.SSM", "PAS", "PSS", "CSS", "OPT", "GSE", "REC", "NEU", "BCS", "PAC", "P", "Es.SCM", "Es.SSM", "Eg.SCM", "Eg.SSM", "Ec.SCM", "Ec.SSM", "CERQSum", "PAS", "age")]
# 
# ###step 2: calculate mean/SD and put into a new dataframe
# ##NOTE: SR... variables are Z-scores, mean of Z-score is always 0 and SD will be 1 -> pointless to calculate?
# Mean = as.data.frame(colMeans(variables.of.interest))
# SD = as.data.frame(apply(variables.of.interest, 2, sd))
# table.mean.sd = cbind(Mean, SD) #combine mean and SD into one table
# colnames(table.mean.sd)[1] <- "Mean" #rename header
# colnames(table.mean.sd)[2] <- "SD" #rename header
# table.mean.sd[, c(1:2)] = table.mean.sd %>% mutate_at(vars(Mean, SD), funs(round(., 2))) #round to two decimals
# 
# ###step 3: use formattable package to create a nice table that can be viewed in the viewer window of R
# formattable(table.mean.sd)
# 
# 
# ######### table 3: intercorrelations of dependent and independent variables
# 
# ###Basic correlation matrix
# corr.matrix = as.data.frame(cor(variables.of.interest, use = "complete.obs")) #intercorrelation matrix
# corr.matrix[, c(1:25)] = corr.matrix %>% mutate_at(vars(c(1:25)), funs(round(., 2))) #round to two decimals
# formattable(corr.matrix, 
#             align = c("c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c", "c") #center values
# )
# 
# ###basic cor(...) does not give p-values, so use rcorr instead (requires more than 4 cases)
# ##variables.of.interest[nrow(variables.of.interest) + 1,] = 1 #testing purpose (needed more than 4 cases, ignore this line) 
# 
# corr.p.matrix <- rcorr(as.matrix(variables.of.interest))
# corr.p.matrix$r #gives correlations
# corr.p.matrix$P #gives p values of correlations
# 
# flattenCorrMatrix <- function(cormat, pmat) { #function to put r and p value into one table
#   ut <- upper.tri(cormat)
#   data.frame(
#     row = rownames(cormat)[row(cormat)[ut]],
#     column = rownames(cormat)[col(cormat)[ut]],
#     cor  =(cormat)[ut],
#     p = pmat[ut]
#   )
# }
# 
# corr.p.matrix <- as.data.frame(flattenCorrMatrix(corr.p.matrix$r, corr.p.matrix$P))
# corr.p.matrix$Sign <- ifelse(corr.p.matrix$p < 0.05, "significant", "not significant") #threshold set at .05
# corr.p.matrix[, c(3,4)] = round(corr.p.matrix[, c(-1, -2, -5)],2) #round 2 decimals, change last value (the 2) if you want more/less decimals
# formattable(corr.p.matrix) #viewer table
# 
# 
# ###helpful intercorrlation matrix graph 
# x = cor(variables.of.interest)
# corrplot(x, type = "lower")
# 
# #
```

```{r check used languages, include=FALSE}
table(data_en$survey.language)
table(data_en$survey.language[which(!is.na(data_en$complete.eu))])
table(data_en$survey.language[which(is.na(data_en$complete.eu))])

# check dates of survey language
min(data_en$Start.DateTime[which(data_en$survey.language=="cs")])
min(data_en$Start.DateTime[which(data_en$survey.language=="da")])
min(data_en$Start.DateTime[which(data_en$survey.language=="de")])
min(data_en$Start.DateTime[which(data_en$survey.language=="en")])
min(data_en$Start.DateTime[which(data_en$survey.language=="es")])
min(data_en$Start.DateTime[which(data_en$survey.language=="et")])
min(data_en$Start.DateTime[which(data_en$survey.language=="fr")])
min(data_en$Start.DateTime[which(data_en$survey.language=="he")])
min(data_en$Start.DateTime[which(data_en$survey.language=="hu")])
min(data_en$Start.DateTime[which(data_en$survey.language=="it")])
min(data_en$Start.DateTime[which(data_en$survey.language=="nl")])
min(data_en$Start.DateTime[which(data_en$survey.language=="no")])
min(data_en$Start.DateTime[which(data_en$survey.language=="pl")])
min(data_en$Start.DateTime[which(data_en$survey.language=="sk")])
min(data_en$Start.DateTime[which(data_en$survey.language=="zh_Hant")])
```

